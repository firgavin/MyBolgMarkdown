---	
title: DataMining_Apriori
grammar_cjkRuby: true
---

# Apriori算法实现
## Apriori简介
Apriori算法是一个经典的数据挖掘算法，Apriori的单词的意思是"先验的"，说明这个算法是具有**先验性质**的，就是说要通过上一次的结果推导出下一次的结果，这个如何体现将会在下面的分析中会慢慢的体现出来。Apriori算法的用处是挖掘频繁项集的，频繁项集粗俗的理解就是找出经常出现的组合，然后根据这些组合最终推出我们的关联规则。

**基本概念:**
**支持度：** 关联规则A->B的支持度<img src="http://chart.googleapis.com/chart?cht=tx&chl= Support=P(AB)" style="border:none;">，指的是事件A和事件B同时发生的概率。
**置信度：** <img src="http://chart.googleapis.com/chart?cht=tx&chl= Confidence=P(B|A)=\frac{P(AB)}{P(A)}" style="border:none;">,指的是发生事件A的基础上发生事件B的概率。
**强规则：** 同时满足最小支持度阈值和最小置信度阈值的规则称为强规则。
**频繁k项集：** 如果事件A中包含k个元素，那么称这个事件A为k项集，并且事件A满足最小支持度阈值的事件称为频繁k项集。

## Apriori定律
为了减少频繁项集的生成时间，应该尽早的消除一些完全不可能是频繁项集的集合。
**Apriori定律1**：如果一个集合是频繁项集，则它的所有子集都是频繁项集。举例：假设一个集合{A,B}是频繁项集，即A、B同时出现在一条记录的次数大于等于最小支持度min_support，则它的子集{A},{B}出现次数必定大于等于min_support，即它的子集都是频繁项集。
**Apriori定律2**：如果一个集合不是频繁项集，则它的所有超集都不是频繁项集。举例：假设集合{A}不是频繁项集，即A出现的次数小于min_support，则它的任何超集如{A,B}出现的次数必定小于min_support，因此其超集必定也不是频繁项集。

## Apriori实现问题
### Apriori伪代码

``` stylus
算法：Apriori
输入：D - 事务数据库；min_sup - 最小支持度计数阈值
输出：L - D中的频繁项集
方法：
     L1=find_frequent_1-itemsets(D); // 找出所有频繁1项集
     For(k=2;Lk-1!=null;k++){
        Ck=apriori_gen(Lk-1); // 产生候选，并剪枝
        For each 事务t in D{ // 扫描D进行候选计数
            Ct =subset(Ck,t); // 得到t的子集
            For each 候选c 属于 Ct
                         c.count++;
        }
        Lk={c属于Ck | c.count>=min_sup}
}
Return L=所有的频繁集；
 
Procedure apriori_gen(Lk-1:frequent(k-1)-itemsets)
      For each项集l1属于Lk-1
              For each项集 l2属于Lk-1
                       If((l1[1]=l2[1])&&( l1[2]=l2[2])&&……..
&& (l1[k-2]=l2[k-2])&&(l1[k-1]<l2[k-1])) then{
                   c=l1连接l2 //连接步：产生候选
                   if has_infrequent_subset(c,Lk-1) then
                       delete c; //剪枝步：删除非频繁候选
                   else add c to Ck;
                  }
          Return Ck;
 
     Procedure has_infrequent_sub(c:candidate k-itemset; Lk-1:frequent(k-1)-itemsets)
        For each(k-1)-subset s of c
            If s不属于Lk-1 then
               Return true;
        Return false;
```

### 连接步
为找出Lk（所有的频繁k项集的集合），通过将Lk-1（所有的频繁k-1项集的集合）与自身连接产生候选k项集的集合。候选集合记作Ck。设l1和l2是Lk-1中的成员。记li[j]表示li中的第j项。假设Apriori算法对事务或项集中的项按字典次序排序，即对于（k-1）项集li，`li[1]<li[2]<……….<li[k-1]`。将Lk-1与自身连接，如果`(l1[1]=l2[1])&&( l1[2]=l2[2])&&……..&& (l1[k-2]=l2[k-2])&&(l1[k-1]<l2[k-1])`，那认为l1和l2是可连接。连接l1和l2 产生的结果是`{l1[1],l1[2],……,l1[k-1],l2[k-1]}`。

### 剪枝步
CK是LK的超集，也就是说，CK的成员可能是也可能不是频繁的。通过扫描所有的事务（交易），确定CK中每个候选的计数，判断是否小于最小支持度计数，如果不是，则认为该候选是频繁的。为了压缩Ck,可以利用Apriori性质：任一频繁项集的所有非空子集也必须是频繁的，反之，如果某个候选的非空子集不是频繁的，那么该候选肯定不是频繁的，从而可以将其从CK中删除。（Tip：为什么要压缩CK：因为实际情况下事务记录往往是保存在外存储上，比如数据库或者其他格式的文件上，在每次计算候选计数时都需要将候选与所有事务进行比对，众所周知，访问外存的效率往往都比较低，因此Apriori加入了所谓的剪枝步，事先对候选集进行过滤，以减少访问外存的次数。）

## Apriori代码实现（Python）

``` python 
# -*- coding: utf-8 -*-

def loadDataSet():
    return [[1, 3, 4], [2, 3, 5], [1, 2, 3, 5], [2, 5]]

def createC1(dataSet):
    '''
    构建初始候选项集的列表,C1是大小为1的所有候选项集的集合
    '''
    C1 = []
    for transaction in dataSet:
        for item in transaction:
            if [item] not in C1:
                C1.append([item])
    C1.sort()
    return map(frozenset, C1)

def scanD(D, Ck, minSupport):
    '''
    计算Ck中的项集在数据集合D(记录或者transactions)中的支持度,
    返回满足最小支持度的项集的集合，和所有项集支持度信息的字典。
    '''
    ssCnt = {}
    for tid in D:
        for can in Ck:
            if can.issubset(tid):
                ssCnt[can] = ssCnt.get(can, 0) + 1
    numItems = float(len(D))
    retList = []
    supportData = {}
    for key in ssCnt:
        # 每个项集的支持度
        support = ssCnt[key] / numItems

        if support >= minSupport:
            retList.insert(0, key)
        supportData[key] = support
    return retList, supportData

def aprioriGen(Lk, k):
    '''
    由初始候选项集的集合Lk生成新的生成候选项集，k表示生成的新项集中所含有的元素个数
    '''
    retList = []
    lenLk = len(Lk)
    for i in range(lenLk):
        for j in range(i + 1, lenLk):
            L1 = list(Lk[i])[: k - 2];
            L2 = list(Lk[j])[: k - 2];
            L1.sort();
            L2.sort()
            if L1 == L2:
                retList.append(Lk[i] | Lk[j])
    return retList

def apriori(dataSet, minSupport=0.5):
    C1 = createC1(dataSet)

    D = map(set, dataSet)
    L1, suppData = scanD(D, C1, minSupport)
    L = [L1]
    # 最初的L1中的每个项集含有一个元素，新生成的.项集应该含有2个元素，所以k=2
    k = 2

    while (len(L[k - 2]) > 0):
        Ck = aprioriGen(L[k - 2], k)
        Lk, supK = scanD(D, Ck, minSupport)

        # 将新的项集的支持度数据加入原来的总支持度字典中
        suppData.update(supK)
        # 将符合最小支持度要求的项集加入L
        L.append(Lk)
        # 新生成的项集中的元素个数应不断增加
        k += 1
    return L, suppData

def calcConf(freqSet, H, supportData, brl, minConf=0.7):
    '''
    计算规则的可信度，返回满足阈值的规则。
    freqSet(frozenset):频繁项集
    H(frozenset):频繁项集中所有的元素
    supportData(dic):频繁项集中所有元素的支持度
    brl(tuple):满足可信度条件的关联规则
    minConf(float):最小可信度
    '''
    prunedH = []
    for conseq in H:
        conf = supportData[freqSet] / supportData[freqSet - conseq]
        if conf >= minConf:
            print freqSet - conseq, '-->', conseq, 'conf:', conf
            brl.append((freqSet - conseq, conseq, conf))
            prunedH.append(conseq)
    return prunedH


def rulesFromConseq(freqSet, H, supportData, brl, minConf=0.7):
    '''
    对频繁项集中元素超过2的项集进行合并。
    freqSet(frozenset):频繁项集
    H(frozenset):频繁项集中的所有元素，即可以出现在规则右部的元素
    supportData(dict):所有项集的支持度信息
    brl(tuple):生成的规则
    '''
    m = len(H[0])

    # 查看频繁项集是否大到移除大小为 m　的子集
    if len(freqSet) > m + 1:
        Hmp1 = aprioriGen(H, m + 1)
        Hmp1 = calcConf(freqSet, Hmp1, supportData, brl, minConf)

        # 如果不止一条规则满足要求，进一步递归合并
        if len(Hmp1) > 1:
            rulesFromConseq(freqSet, Hmp1, supportData, brl, minConf)


def generateRules(L, supportData, minConf=0.7):
    '''
    根据频繁项集和阈值生成规则。
    L(list):存储频繁项集
    supportData(dict):存储着所有项集（不仅仅是频繁项集）的支持度
    minConf(float):最小可信度
    '''
    bigRuleList = []
    for i in range(1, len(L)):
        for freqSet in L[i]:
            # 对于每一个频繁项集的集合freqSet
            H1 = [frozenset([item]) for item in freqSet]
            # 如果频繁项集中的元素个数大于2，需要进一步合并
            if i > 1:
                rulesFromConseq(freqSet, H1, supportData, bigRuleList, minConf)
            else:
                calcConf(freqSet, H1, supportData, bigRuleList, minConf)
    return bigRuleList


if __name__ == '__main__':
    # 导入数据集
    myDat = loadDataSet()
    # 选择频繁项集
    L, suppData = apriori(myDat, 0.5)
    # 生成规则
    rules = generateRules(L, suppData, minConf=0.7)
    print 'rules:\n', rules
```
> 阈值是0.7时：

![enter description here][1]

> 阈值是0.5时：

![enter description here][2]


  [1]: ./images/1497172715423.jpg "1497172715423.jpg"
  [2]: ./images/1497172689844.jpg "1497172689844.jpg"